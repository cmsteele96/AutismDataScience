{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23f1a75",
   "metadata": {},
   "source": [
    "Let's build a better model to predict autism in adults (aged 18+) and analyze its performance!\n",
    "\n",
    "\"Class/ASD\" is the result of scoring 7 or more among the A1 - A10 columns (values are binary; that is, they are answered as 1 or 0). The \"austim\" (misspelled in the source dataset, later renamed correctly to \"autism\") is the assumed true value, where the individuals self-disclose whether they have already been diagnosed with autism.\n",
    "\n",
    "Actual questions for A1-A10 is shown below after displaying the dataset.\n",
    "\n",
    "Key to the questionnaire and its source: https://wchh.onlinelibrary.wiley.com/doi/10.1002/psb.1816\n",
    "\n",
    "The dataset and more information: \n",
    "https://www.kaggle.com/datasets/andrewmvd/autism-screening-on-adults\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfaacb9",
   "metadata": {},
   "source": [
    "<b>Part 1. Exploratory data analysis</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f17d30",
   "metadata": {},
   "source": [
    "Before doing anything, let's import some typical libraries and take a look at the dataset, the column names, datatypes of each column, and see if there are any missing values or outliers we should take care of first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import libraries to get started\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31267daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the dataset and take a look\n",
    "\n",
    "# I'll keep a copy of the raw data first\n",
    "df_raw = pd.read_csv(\"Autism_Dataraw.csv\")\n",
    "\n",
    "# Let's work with 'df'\n",
    "df = df_raw\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e101815",
   "metadata": {},
   "source": [
    "For reference on the A1 - A10 scores, according to the questionnaire:\n",
    "\n",
    "\n",
    "\"SCORING: Only 1 point can be scored for each question. Score 1 point for Definitely or Slightly agree on each of items 1, 7, 8, and 10. Score 1 point for Definitely or Slightly Disagree on each of items 2, 3, 4, 5, 6, and 9. If the individual scores more than 6 out of 10, consider referring them for a specialist diagnostic assessment.\"\n",
    " \n",
    "\"Please tick one option per question only:\n",
    "Definitely agree\n",
    "Slightly agree\n",
    "Slightly disagree\n",
    "Definitely disagree\"\n",
    "\n",
    "1\n",
    "I often notice small sounds when others do not.\n",
    " \n",
    "2\n",
    "I usually concentrate more on the whole picture, rather than the small details.\n",
    "   \n",
    "3\n",
    "I find it easy to do more than one thing at once\n",
    "  \n",
    "4\n",
    "If there is an interruption, I can switch back to what I was doing very quickly\n",
    "  \n",
    "5\n",
    "I find it easy to ‘read between the lines’ when someone is talking to me\n",
    " \n",
    "6\n",
    "I know how to tell if someone listening to me is getting bored\n",
    " \n",
    "7\n",
    "When I’m reading a story I find it difficult to work out the characters’ intentions\n",
    " \n",
    "8\n",
    "I like to collect information about categories of things (e.g. types of car, bird, train, plant etc.)\n",
    " \n",
    "9\n",
    "I find it easy to work out what someone is thinking or feeling just by looking at their face\n",
    "  \n",
    "10\n",
    "I find it difficult to work out people’s intentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3cc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at all the columns to see \n",
    "# what we're working with\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's correct some column misspellings\n",
    "df = df.rename(\n",
    "    {'austim': 'autism',\n",
    "     'jundice': 'jaundice',\n",
    "     'contry_of_res': 'country_of_res'},\n",
    "    axis = 'columns'\n",
    ")\n",
    "\n",
    "# Check to see if all columns are now spelled correctly\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6635444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the datatypes of each?\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387977c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"object\" type columns may indicate some issues\n",
    "# regarding columns that presumably should be int64,\n",
    "# like the age column. So let's clean the data.\n",
    "# To start, are there any missing values?\n",
    "print('Total missing values:', df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ead7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, but I noticed there are many values\n",
    "# with a '?'. What columns contain a '?'?\n",
    "df.columns[df.isin(['?']).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take care of these, starting with age.\n",
    "\n",
    "# Briefly describe the age column\n",
    "display(df['age'].describe())\n",
    "\n",
    "# What type of values are in the age column?\n",
    "display(df['age'].apply(type).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On first glance it can be seen above that 21 is the\n",
    "# most common age group that took this questionnaire, \n",
    "# among 47 different ages. The str type probably is \n",
    "# due to the presence of the '?'. Let's show the \n",
    "# unique age values.\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97139224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's age 383 once and age '?' twice.\n",
    "# Considering these are a total of 3 values,\n",
    "# I consider this relatively insignificant.\n",
    "# Let's replace these with the mode age.\n",
    "\n",
    "# Determine the mode(age)\n",
    "age_mode = int(df['age'].mode()[0])\n",
    "print('Mode of age column:', age_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66085974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the '?' with the mode.\n",
    "df['age']= df['age'].replace({'?': age_mode})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9001c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can change the datatype of the \n",
    "# age column values to int, so that we can\n",
    "# then replace the 383 value with the mode.\n",
    "df['age'] = (df['age'].values.astype(int))\n",
    "df['age']= df['age'].replace({383: age_mode})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67652364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if age column is cleansed\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's investigate ethnicity.\n",
    "# What are its value counts?\n",
    "df['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many issues here. First we can \n",
    "# combine \"others\" with \"Others\"\n",
    "df['ethnicity'] = df['ethnicity'].replace('others', 'Others')\n",
    "\n",
    "# Check\n",
    "df['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97531973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the quotations ''\n",
    "df['ethnicity'] = df['ethnicity'].str.strip(\"''\")\n",
    "\n",
    "# Check\n",
    "df['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd69b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could replace '?' with the mode (White-European),\n",
    "# but this may come acrossed as a form as bias.\n",
    "# To get some more insight, let's look at \n",
    "# country of residence.\n",
    "df['country_of_res'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of the quotations\n",
    "df['country_of_res'] = df['country_of_res'].str.strip(\"''\")\n",
    "df['country_of_res'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcad8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the country of residence column has no '?'values\n",
    "df[df['country_of_res'] == '?']['country_of_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3b5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a closer look at how many \"?\" per country\n",
    "df[['country_of_res', 'ethnicity']].sort_values(['country_of_res', 'ethnicity'], ascending = True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be seen that some countries don't have any ethnicities.\n",
    "# So let's replace those that have ? with the most common\n",
    "# ethnicity in that country. If a country has all '?', replacing with \n",
    "# 'Others' seems like a reasonable assumption.\n",
    "df['ethnicity'] =df.groupby('country_of_res')['ethnicity'].apply(\n",
    "    lambda x: x.replace('?', 'Others') if (x == '?').all() else x.replace('?', x[x != '?'].mode()[0])\n",
    ")\n",
    "\n",
    "# Check there are no more '?'\n",
    "df['ethnicity'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4eedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's see these two columns again\n",
    "df[['country_of_res', 'ethnicity']].sort_values(['country_of_res', 'ethnicity'], ascending = True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fe344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking good. Now, the last column with '?' is relation.\n",
    "# Lets look\n",
    "df['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6669e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual let's strip any quotations.\n",
    "df['relation'] = df['relation'].str.strip(\"''\")\n",
    "df['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69691c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relation is who is taking the test. There doesn't seem to be\n",
    "# any other columns that give us clues as to what to fill these with.\n",
    "# So we'll go ahead and replace with 'Unknown' for clarity.\n",
    "df['relation'] =df['relation'].replace('?', 'Unknown')\n",
    "df['relation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check to see there are no more '?'\n",
    "df[df.values == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a final bird's eye view to check value counts\n",
    "# for each.\n",
    "for column in df.columns:\n",
    "    print(df[column].value_counts())\n",
    "    \n",
    "    # for spacing\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_desc is constant. We can drop this.\n",
    "\n",
    "# Should be true if all values in age_desc are the same\n",
    "display(df.shape[0] == df['age_desc'].value_counts()[0])\n",
    "df = df.drop('age_desc', axis = \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b615b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, for consistency, let's lowercase the Class/ASD column.\n",
    "df['Class/ASD']=df['Class/ASD'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's revisit our columns and ensure everything is clean.\n",
    "display(df.columns)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227a73e",
   "metadata": {},
   "source": [
    "<b> Part 2. How accurate is the questionnaire? </b>\n",
    "Before implementing a better model, let's analyze how well the questionnaire alone did at predicting autism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc4ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's calculate how many times the questionnaire was off.\n",
    "\n",
    "# Show first few rows of columns we are comparing\n",
    "display(df[['autism', 'Class/ASD']].head())\n",
    "\n",
    "# Number of correct classifications from the questionnaire\n",
    "num_correct_from_q = np.count_nonzero(\n",
    "    df['autism'] == df['Class/ASD']\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "print(\"Number of correct classifications:\", num_correct_from_q, \"out of\", df.shape[0])\n",
    "print(\"Percentage correct:\", np.round(num_correct_from_q/df.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualize the error.\n",
    "\n",
    "# Import some more libraries.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd726a5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "conf_matrix_original = confusion_matrix(df['autism'], df['Class/ASD'], labels=['yes', 'no'])\n",
    "\n",
    "# Visualization using Seaborn heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_original, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted Yes', 'Predicted No'], \n",
    "            yticklabels=['True Yes', 'True No'])\n",
    "plt.title('Confusion Matrix between Actual and Predicted Autism from Questionnaire Alone')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8076dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the model better than random?\n",
    "\n",
    "# Compute the kappa statistic\n",
    "questionnaire_kappa_stat = cohen_kappa_score(df['autism'],df['Class/ASD'])\n",
    "questionnaire_kappa_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4fe73",
   "metadata": {},
   "source": [
    "The model is slightly better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualized another way\n",
    "# Create a count of true/false predictions\n",
    "comparison_counts = df.groupby(['autism', 'Class/ASD']).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "# Replace \"yes\" and \"no\" in the 'autism' column with the desired labels\n",
    "label_map_autism = {'yes': 'autistic', 'no': 'not autistic'}\n",
    "comparison_counts['autism'] = comparison_counts['autism'].map(label_map_autism)\n",
    "\n",
    "# Replace \"yes\" and \"no\" in the 'Class/ASD' column with 'autistic' and 'not autistic'\n",
    "label_map_class = {'yes': 'autistic', 'no': 'not autistic'}\n",
    "comparison_counts['Class/ASD'] = comparison_counts['Class/ASD'].map(label_map_class)\n",
    "\n",
    "\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='autism', y='count', hue='Class/ASD', data=comparison_counts)\n",
    "plt.title('Comparison of True (Autism) and Predicted (Class/ASD)')\n",
    "plt.xlabel('Type of patient (from actual diagnosis)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Questionnaire Prediction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0002c34b",
   "metadata": {},
   "source": [
    "It can be seen now that the questionnaire predicts autistic patients better than non-autistic. The questionnaire is also slighty better than random. It would benefit if the dataset were larger, but this is what we have to work with. Let's see if we can at least improve the predictions for non-autistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac952a1e",
   "metadata": {},
   "source": [
    "<b> Part 3. Building a better model </b> Now let's see if we can increase the percentage of correctly classified patients using the dataframe we cleansed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1bd6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataframe again for convenience\n",
    "display(df.head())\n",
    "display(df.columns)\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3ac80",
   "metadata": {},
   "source": [
    "Let's determine what features to use in our model. Let's go one by one, starting with ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A visualization might help.\n",
    "\n",
    "# Create a count plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='ethnicity', hue='autism')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Ethnicity by Autism Status', fontsize=16)\n",
    "plt.xlabel('Ethnicity', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Autism', loc='upper right', labels=['No', 'Yes'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d7522",
   "metadata": {},
   "source": [
    "It may appear that Latinos have a higher rate of autism, but it's a small sample size. Therefore it appears ethnicity has little to do with autism. What about jaundice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315fe088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='jaundice', hue='autism')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Jaundice Status Among Individuals with Autism', fontsize=16)\n",
    "plt.xlabel('Jaundice', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Autism', loc='upper right', labels=['No', 'Yes'])\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1c7c2",
   "metadata": {},
   "source": [
    "It may be that those with autism tend to have jaundice. But again, not much of an association given the small sample size.  Let's try age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the age bins\n",
    "bins = range(0, df['age'].max() + 10, 10)  # Adjust based on max age\n",
    "labels = [f\"{i}-{i+9}\" for i in bins[:-1]]  # Create labels for the bins\n",
    "\n",
    "# Create a count plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=df, x=pd.cut(df['age'], bins=bins, labels=labels, right=False), hue='autism')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Autism by Age Groups', fontsize=16)\n",
    "plt.xlabel('Age Group', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Autism', loc='upper right', labels=['No', 'Yes'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1eacf8",
   "metadata": {},
   "source": [
    "It appears there may be something going on within the 30-39 age group. These seem to have a higher rate of autism, but again this is a small sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c20cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for gender vs autism\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df, x='gender', hue='autism')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Autism by Gender', fontsize=16)\n",
    "plt.xlabel('Gender', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Autism', loc='upper right', labels=['No', 'Yes'])\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aaa496",
   "metadata": {},
   "source": [
    "As shown, females appear to have a higher rate of autism. Now let's analyze each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of questions\n",
    "questions = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', \n",
    "             'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']\n",
    "\n",
    "# Initialize a list to store percent correct\n",
    "percent_correct = []\n",
    "\n",
    "# Loop through each question and calculate percent correct\n",
    "for question in questions:\n",
    "    percent = np.count_nonzero(df[df['autism'] == 'yes'][question] == 1) / len(df[df['autism'] == 'yes']) * 100\n",
    "    percent_correct.append(percent)  # Append the result to the list\n",
    "\n",
    "# Store these as a new DataFrame\n",
    "most_predictive_questions = pd.DataFrame(\n",
    "    {'Question': questions,\n",
    "     \"autistic_percent_answered_'1'\": percent_correct\n",
    "    }\n",
    ").sort_values(\"autistic_percent_answered_'1'\", ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "most_predictive_questions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557c84d",
   "metadata": {},
   "source": [
    "Shown above are the questions sorted in descending order by most predictive questions (potentially). Note that per the key, questions could mean either agree or disagree depending on the question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2dac86",
   "metadata": {},
   "source": [
    "Given everything we've learned about this dataset, let's try some modeling, starting with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a76d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's encode some features as binary\n",
    "df['jaundice_binary'] = df['jaundice'].map({'yes': 1, 'no': 0})\n",
    "df['autism_binary'] = df['autism'].map({'yes': 1, 'no': 0})\n",
    "df['is_female'] = df['gender'].map({'f': 1, 'm': 0})\n",
    "df['is_male'] = df['gender'].map({'m': 1, 'f': 0})\n",
    "df['class_binary'] = df['Class/ASD'].map({'yes': 1, 'no':0})\n",
    "\n",
    "# According to the key, scores greater than 6 are suggested to\n",
    "# be referred to a health professional\n",
    "df['score_more_than_6'] = (df['result'] > 6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a933bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary columns for each specific age bin\n",
    "df['is_10_to_19_yrs_old'] = ((df['age'] >= 10) & (df['age'] <= 19)).astype(int)\n",
    "df['is_20_to_29_yrs_old'] = ((df['age'] >= 20) & (df['age'] <= 29)).astype(int)\n",
    "df['is_30_to_39_yrs_old'] = ((df['age'] >= 30) & (df['age'] <= 39)).astype(int)\n",
    "df['is_40_to_49_yrs_old'] = ((df['age'] >= 40) & (df['age'] <= 49)).astype(int)\n",
    "df['is_50_to_59_yrs_old'] = ((df['age'] >= 50) & (df['age'] <= 59)).astype(int)\n",
    "df['is_60_to_69_yrs_old'] = ((df['age'] >= 60) & (df['age'] <= 69)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the ethnicities and store \n",
    "df= pd.get_dummies(df, columns=['ethnicity'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcbbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the dataframe\n",
    "display(df.head())\n",
    "display(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ad0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like Middle Eastern has a slight typo\n",
    "df.rename(columns={'Middle Eastern ': 'Middle Eastern'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5734c0b7",
   "metadata": {},
   "source": [
    "Now, let's use feature selection to determine what features have the most potential predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69514ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all binary features\n",
    "features = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score',\n",
    "            'A5_Score', 'A6_Score','A7_Score', 'A8_Score',\n",
    "            'A9_Score', 'A10_Score','jaundice_binary',\n",
    "            'is_female', 'is_male',\n",
    "            'score_more_than_6','is_10_to_19_yrs_old',\n",
    "            'is_20_to_29_yrs_old', 'is_30_to_39_yrs_old',\n",
    "            'is_40_to_49_yrs_old', 'is_50_to_59_yrs_old',\n",
    "            'is_60_to_69_yrs_old','Asian', 'Black',\n",
    "            'Hispanic', 'Latino', 'Middle Eastern',\n",
    "            'Others','Pasifika', 'South Asian', 'Turkish',\n",
    "            'White-European']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8279816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d455df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Assuming X and y are defined as before\n",
    "selector = SelectKBest(score_func=chi2, k='all')  # You can specify the number of features with k\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Get the scores and features\n",
    "chi2_scores = selector.scores_\n",
    "features = X.columns[selector.get_support()]\n",
    "\n",
    "# Display feature scores\n",
    "for feature, score in zip(X.columns, chi2_scores):\n",
    "    print(f\"{feature}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892a92a",
   "metadata": {},
   "source": [
    "It looks like we should add more features. Let's try to get our model closer to, and ideally greater than (in terms of absolute value), the original kappa stat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d85b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)  # Choose the number of features to keep\n",
    "rfe.fit(X, y)\n",
    "\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected features: {selected_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fb52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importances.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how these two features do.\n",
    "features = ['jaundice_binary','is_female', 'is_male', 'score_more_than_6',\n",
    "       'is_10_to_19_yrs_old', 'is_20_to_29_yrs_old', 'is_30_to_39_yrs_old',\n",
    "       'is_40_to_49_yrs_old', 'is_50_to_59_yrs_old', 'is_60_to_69_yrs_old',]\n",
    "target = 'autism_binary'\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df[features]\n",
    "y = df[target] \n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create confusion matrix for logistic regression\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix for logistic regression\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted No', 'Predicted Yes'], \n",
    "            yticklabels=['True No', 'True Yes'])  # Consistent labeling\n",
    "plt.title('Confusion Matrix for Autism Prediction (Logistic Regression)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print the confusion matrix for logistic regression\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Kappa stat:\", cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "# Create confusion matrix for original data\n",
    "conf_matrix_original = confusion_matrix(df['autism'], df['Class/ASD'], labels=['no', 'yes'])\n",
    "\n",
    "# Display confusion matrix for original data\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_original, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted No', 'Predicted Yes'], \n",
    "            yticklabels=['True No', 'True Yes'])  # Consistent labeling\n",
    "plt.title('Confusion Matrix between Actual and Predicted Autism from Questionnaire')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print the confusion matrix for original data\n",
    "print(\"Original Confusion Matrix:\\n\", conf_matrix_original)\n",
    "print(\"Original kappa stat:\", questionnaire_kappa_stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06dfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume df is your DataFrame and 'jaundice' is already encoded as 0 or 1.\n",
    "features = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', \n",
    "            'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score',\n",
    "            'jaundice_binary','is_30_to_39_yrs_old', 'is_female', 'is_male',\n",
    "            'Asian', 'Black','Hispanic', 'Latino', 'Middle Eastern ',\n",
    "            'Others', 'Pasifika','South Asian', 'Turkish',\n",
    "            'White-European']\n",
    "target = 'autism_binary'\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df_one_hot[features]\n",
    "y = df_one_hot[target] \n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted No', 'Predicted Yes'], \n",
    "            yticklabels=['True No', 'True Yes'])\n",
    "plt.title('Confusion Matrix for Autism Prediction')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Kappa stat:\", cohen_kappa_score(y_test,y_pred))\n",
    "print(\"Questionnaire kappa stat:\", questionnaire_kappa_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume df is your DataFrame and 'jaundice' is already encoded as 0 or 1.\n",
    "features = ['class_binary','jaundice_binary', 'is_female', 'is_male',\n",
    "            'Asian', 'Black','Hispanic', 'Latino', 'Middle Eastern ',\n",
    "            'Others', 'Pasifika','South Asian', 'Turkish',\n",
    "            'White-European']\n",
    "target = 'autism_binary'\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df_one_hot[features]\n",
    "y = df_one_hot[target] \n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted No', 'Predicted Yes'], \n",
    "            yticklabels=['True No', 'True Yes'])\n",
    "plt.title('Confusion Matrix for Autism Prediction')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Kappa stat:\", cohen_kappa_score(y_test,y_pred))\n",
    "print(\"Questionnaire kappa stat:\", questionnaire_kappa_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ccfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Features and target from your dataset\n",
    "features = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', \n",
    "            'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score',\n",
    "            'jaundice_binary', 'is_female', 'is_male', 'Asian', 'Black','Hispanic', 'Latino', 'Middle Eastern ',\n",
    "            'Others', 'Pasifika','South Asian', 'Turkish',\n",
    "            'White-European', 'is_30_to_39_yrs_old']\n",
    "target = 'autism_binary'\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df_one_hot[features]\n",
    "y = df_one_hot[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Decision Tree model\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix with a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted No', 'Predicted Yes'], \n",
    "            yticklabels=['True No', 'True Yes'])\n",
    "plt.title('Confusion Matrix for Autism Prediction (Decision Tree)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Questionnaire kappa stat:\", questionnaire_kappa_stat)\n",
    "print(\"This Model's kappa stat:\", cohen_kappa_score((y_test), (y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16991560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Features and target from your dataset\n",
    "features = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', \n",
    "            'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score',\n",
    "            'jaundice_binary', 'is_female', 'is_male', 'Asian', 'Black','Hispanic', 'Latino', 'Middle Eastern ',\n",
    "            'Others', 'Pasifika','South Asian', 'Turkish',\n",
    "            'White-European']\n",
    "target = 'autism_binary'\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df_one_hot[features]\n",
    "y = df_one_hot[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Decision Tree model\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix with a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted No', 'Predicted Yes'], \n",
    "            yticklabels=['True No', 'True Yes'])\n",
    "plt.title('Confusion Matrix for Autism Prediction (Decision Tree)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Print the confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Questionnaire kappa stat:\", questionnaire_kappa_stat)\n",
    "print(\"This Model's kappa stat:\", cohen_kappa_score((y_test), (y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e1e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
